import json
import os
import numpy as np
import matplotlib.pyplot as plt
import argparse
from pathlib import Path


def load_metrics(metrics_file):
    """åŠ è½½è®­ç»ƒæŒ‡æ ‡æ–‡ä»¶"""
    with open(metrics_file, 'r') as f:
        metrics = json.load(f)
    return metrics


def smooth_curve(points, factor=0.8):
    """å¹³æ»‘æ›²çº¿ï¼Œç”¨äºæ›´æ¸…æ™°åœ°å±•ç¤ºè¶‹åŠ¿"""
    smoothed_points = []
    for point in points:
        if smoothed_points:
            previous = smoothed_points[-1]
            smoothed_points.append(previous * factor + point * (1 - factor))
        else:
            smoothed_points.append(point)
    return smoothed_points


def analyze_metrics(metrics_file, output_dir=None, smooth=True):
    """åˆ†æè®­ç»ƒæŒ‡æ ‡å¹¶ç”Ÿæˆè¯Šæ–­å›¾è¡¨"""
    # åŠ è½½æŒ‡æ ‡
    print(f"åŠ è½½æŒ‡æ ‡æ–‡ä»¶: {metrics_file}")
    metrics = load_metrics(metrics_file)
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = os.path.join(os.path.dirname(metrics_file), "analysis")
    os.makedirs(output_dir, exist_ok=True)
    print(f"åˆ†æç»“æœå°†ä¿å­˜åˆ°: {output_dir}")
    
    # æå–å…³é”®æŒ‡æ ‡
    timesteps = np.array(metrics["timesteps"])
    mean_rewards = np.array(metrics["mean_reward"])
    mean_ep_lengths = np.array(metrics["mean_ep_length"])
    value_losses = np.array(metrics["value_loss"])
    policy_losses = np.array(metrics["policy_loss"])
    explained_vars = np.array(metrics["explained_variance"])
    entropies = np.array(metrics["entropy_loss"])
    kl_divs = np.array(metrics["approx_kl"])
    
    # æ‰“å°åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print("\n===== è®­ç»ƒç»Ÿè®¡ä¿¡æ¯ =====")
    print(f"æ€»è®­ç»ƒæ­¥æ•°: {timesteps[-1]}")
    print(f"æœ€ç»ˆå¹³å‡å¥–åŠ±: {mean_rewards[-1]:.2f}")
    print(f"æœ€é«˜å¹³å‡å¥–åŠ±: {np.max(mean_rewards):.2f}")
    print(f"æœ€ç»ˆå›åˆé•¿åº¦: {mean_ep_lengths[-1]:.2f}")
    print(f"æœ€ç»ˆå€¼å‡½æ•°æŸå¤±: {value_losses[-1]:.2f}")
    print(f"æœ€ç»ˆç­–ç•¥æŸå¤±: {policy_losses[-1]:.5f}")
    print(f"æœ€ç»ˆè§£é‡Šæ–¹å·®: {explained_vars[-1]:.5f}")
    
    # æ£€æµ‹è®­ç»ƒé—®é¢˜
    print("\n===== è®­ç»ƒè¯Šæ–­ =====")
    
    # æ£€æŸ¥å¥–åŠ±è¶‹åŠ¿
    reward_trend = np.polyfit(range(len(mean_rewards[-10:])), mean_rewards[-10:], 1)[0]
    if reward_trend < 0:
        print("âš ï¸ è­¦å‘Š: å¥–åŠ±åœ¨è®­ç»ƒæœ«æœŸå‘ˆä¸‹é™è¶‹åŠ¿")
    elif reward_trend > 0 and mean_rewards[-1] < 195:
        print("â„¹ï¸ ä¿¡æ¯: å¥–åŠ±åœ¨è®­ç»ƒæœ«æœŸä»åœ¨ä¸Šå‡ï¼Œå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´è®­ç»ƒ")
        
    # æ£€æŸ¥å€¼å‡½æ•°æŸå¤±
    if value_losses[-1] > 1000:
        print("âš ï¸ è­¦å‘Š: å€¼å‡½æ•°æŸå¤±è¾ƒé«˜ï¼Œè¡¨æ˜å€¼å‡½æ•°é¢„æµ‹ä¸å‡†ç¡®")
        
    # æ£€æŸ¥è§£é‡Šæ–¹å·®
    if explained_vars[-1] < 0:
        print("âš ï¸ è­¦å‘Š: è§£é‡Šæ–¹å·®ä¸ºè´Ÿï¼Œè¡¨æ˜å€¼å‡½æ•°é¢„æµ‹è´¨é‡å·®")
    elif explained_vars[-1] < 0.5:
        print("âš ï¸ è­¦å‘Š: è§£é‡Šæ–¹å·®è¾ƒä½ï¼Œå€¼å‡½æ•°å¯èƒ½éœ€è¦æ”¹è¿›")
        
    # æ£€æŸ¥KLæ•£åº¦
    if np.mean(kl_divs[-10:]) > 0.05:
        print("âš ï¸ è­¦å‘Š: KLæ•£åº¦è¾ƒå¤§ï¼Œç­–ç•¥æ›´æ–°å¯èƒ½è¿‡äºæ¿€è¿›")
    elif np.mean(kl_divs[-10:]) < 0.001:
        print("âš ï¸ è­¦å‘Š: KLæ•£åº¦è¾ƒå°ï¼Œå­¦ä¹ å¯èƒ½è¿‡äºä¿å®ˆ")
        
    # æ£€æŸ¥ç†µæŸå¤±
    if entropies[-1] > -0.5:
        print("âš ï¸ è­¦å‘Š: ç†µè¾ƒé«˜ï¼Œç­–ç•¥å¯èƒ½è¿‡äºä¸ç¡®å®š")
    elif entropies[-1] < -2:
        print("âš ï¸ è­¦å‘Š: ç†µè¾ƒä½ï¼Œç­–ç•¥å¯èƒ½è¿‡æ—©æ”¶æ•›")
        
    # ç»˜åˆ¶è¯Šæ–­å›¾è¡¨
    plt.figure(figsize=(15, 10))
    
    # å¥–åŠ±æ›²çº¿
    plt.subplot(2, 2, 1)
    if smooth:
        plt.plot(timesteps, smooth_curve(mean_rewards), label='å¹³æ»‘')
    plt.plot(timesteps, mean_rewards, alpha=0.3, label='åŸå§‹')
    plt.grid(True)
    plt.title('å¹³å‡å¥–åŠ±')
    plt.xlabel('è®­ç»ƒæ­¥æ•°')
    plt.ylabel('å¥–åŠ±')
    plt.legend()
    
    # å›åˆé•¿åº¦æ›²çº¿
    plt.subplot(2, 2, 2)
    if smooth:
        plt.plot(timesteps, smooth_curve(mean_ep_lengths), label='å¹³æ»‘')
    plt.plot(timesteps, mean_ep_lengths, alpha=0.3, label='åŸå§‹')
    plt.grid(True)
    plt.title('å¹³å‡å›åˆé•¿åº¦')
    plt.xlabel('è®­ç»ƒæ­¥æ•°')
    plt.ylabel('æ­¥æ•°')
    plt.legend()
    
    # æŸå¤±æ›²çº¿
    plt.subplot(2, 2, 3)
    if smooth:
        plt.plot(timesteps, smooth_curve(value_losses), label='å€¼å‡½æ•°æŸå¤±(å¹³æ»‘)')
        plt.plot(timesteps, smooth_curve(policy_losses), label='ç­–ç•¥æŸå¤±(å¹³æ»‘)')
    else:
        plt.plot(timesteps, value_losses, label='å€¼å‡½æ•°æŸå¤±')
        plt.plot(timesteps, policy_losses, label='ç­–ç•¥æŸå¤±')
    plt.grid(True)
    plt.title('æŸå¤±æ›²çº¿')
    plt.xlabel('è®­ç»ƒæ­¥æ•°')
    plt.ylabel('æŸå¤±')
    plt.legend()
    
    # è§£é‡Šæ–¹å·®
    plt.subplot(2, 2, 4)
    plt.plot(timesteps, explained_vars)
    plt.grid(True)
    plt.axhline(y=0, color='r', linestyle='-')
    plt.title('è§£é‡Šæ–¹å·®')
    plt.xlabel('è®­ç»ƒæ­¥æ•°')
    plt.ylabel('æ–¹å·®')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'main_metrics.png'))
    
    # ç»˜åˆ¶å…¶ä»–æŒ‡æ ‡
    plt.figure(figsize=(15, 8))
    
    # KLæ•£åº¦
    plt.subplot(2, 2, 1)
    plt.plot(timesteps, kl_divs)
    plt.grid(True)
    plt.title('KLæ•£åº¦')
    plt.xlabel('è®­ç»ƒæ­¥æ•°')
    plt.ylabel('KL')
    
    # ç†µæŸå¤±
    plt.subplot(2, 2, 2)
    plt.plot(timesteps, entropies)
    plt.grid(True)
    plt.title('ç†µæŸå¤±')
    plt.xlabel('è®­ç»ƒæ­¥æ•°')
    plt.ylabel('ç†µ')
    
    # å‰ªåˆ‡åˆ†æ•°
    plt.subplot(2, 2, 3)
    plt.plot(timesteps, metrics["clip_fraction"])
    plt.grid(True)
    plt.title('å‰ªåˆ‡åˆ†æ•°')
    plt.xlabel('è®­ç»ƒæ­¥æ•°')
    plt.ylabel('æ¯”ä¾‹')
    
    # å­¦ä¹ ç‡
    plt.subplot(2, 2, 4)
    plt.plot(timesteps, metrics["learning_rate"])
    plt.grid(True)
    plt.title('å­¦ä¹ ç‡')
    plt.xlabel('è®­ç»ƒæ­¥æ•°')
    plt.ylabel('å­¦ä¹ ç‡')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'additional_metrics.png'))
    
    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    print("\n===== ä¼˜åŒ–å»ºè®® =====")
    
    # åŸºäºå¥–åŠ±åˆ†æ
    if np.max(mean_rewards) < 150:
        print("ğŸ”„ è€ƒè™‘å¢åŠ è®­ç»ƒæ­¥æ•°ï¼Œå½“å‰å¥–åŠ±æ°´å¹³è¾ƒä½")
        
    # åŸºäºå€¼å‡½æ•°åˆ†æ
    if explained_vars[-1] < 0.5:
        print("ğŸ”„ è€ƒè™‘è°ƒæ•´ç½‘ç»œæ¶æ„ï¼Œå¢å¼ºå€¼å‡½æ•°ç½‘ç»œèƒ½åŠ›")
        print("   - å¢åŠ å€¼å‡½æ•°ç½‘ç»œçš„å®½åº¦å’Œæ·±åº¦")
        print("   - è€ƒè™‘ä½¿ç”¨ä¸åŒçš„æ¿€æ´»å‡½æ•°ï¼Œå¦‚LeakyReLU")
        print("   - è°ƒæ•´vf_coefå‚æ•°ï¼Œå¢åŠ å€¼å‡½æ•°çš„æ›´æ–°æƒé‡")
    
    # åŸºäºKLæ•£åº¦åˆ†æ
    if np.mean(kl_divs[-10:]) > 0.05:
        print("ğŸ”„ ç­–ç•¥æ›´æ–°å¯èƒ½è¿‡äºæ¿€è¿›")
        print("   - å‡å°å­¦ä¹ ç‡")
        print("   - å¢å¤§clip_range")
    elif np.mean(kl_divs[-10:]) < 0.001:
        print("ğŸ”„ ç­–ç•¥æ›´æ–°å¯èƒ½è¿‡äºä¿å®ˆ")
        print("   - å¢å¤§å­¦ä¹ ç‡")
        print("   - å‡å°clip_range")
    
    # åŸºäºç†µåˆ†æ
    if entropies[-1] > -0.5:
        print("ğŸ”„ ç­–ç•¥å¯èƒ½è¿‡äºä¸ç¡®å®š")
        print("   - å‡å°ent_coefï¼Œé™ä½æ¢ç´¢ç¨‹åº¦")
    elif entropies[-1] < -2:
        print("ğŸ”„ ç­–ç•¥å¯èƒ½è¿‡æ—©æ”¶æ•›")
        print("   - å¢å¤§ent_coefï¼Œå¢åŠ æ¢ç´¢")
    
    print("\nåˆ†æå®Œæˆï¼")
    return metrics


def main():
    parser = argparse.ArgumentParser(description='åˆ†æPPOè®­ç»ƒæŒ‡æ ‡')
    parser.add_argument('--metrics_file', type=str, default='./metrics/training_metrics.json',
                        help='è®­ç»ƒæŒ‡æ ‡JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default=None,
                        help='åˆ†æç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--no_smooth', action='store_true',
                        help='ä¸å¹³æ»‘æ›²çº¿')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.metrics_file):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æŒ‡æ ‡æ–‡ä»¶ {args.metrics_file}")
        return
    
    analyze_metrics(args.metrics_file, args.output_dir, not args.no_smooth)


if __name__ == "__main__":
    main() 